{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EASI-FISH pipeline tutorial\n",
    "---\n",
    "\n",
    "This tutorial shows the basic requirements for running the pre-packaged easi-fish registration pipeline. Although we will only be running a few functions in this tutorial, a lot of complex things are happening behind the scenes. At the end of the tutorial I will recommend another tutorial and more reading to learn about those behing-the-scenes components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define inputs\n",
    "---\n",
    "\n",
    "We will need a low resolution and high resolution datasets for our fixed and moving images. The low resolution datasets will be used for global alignment and the high resolution datasets will be used for local alignment corrections. It's assumed that the datasets do not fit into memory so they are all \"lazy loaded\" with zarr. Of course, we also need to know the voxel sampling rate in microns, so that is extracted from the image file metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data\n",
    "import numpy as np\n",
    "import zarr, tifffile\n",
    "\n",
    "# file paths to tutorial data N5 files\n",
    "# replace capitalized text in paths below with the location where you cloned bigstream\n",
    "fix_path = '/PATH/TO/BIGSTREAM/REPOSITORY/resources/fix.n5'\n",
    "mov_path = '/PATH/TO/BIGSTREAM/REPOSITORY/resources/mov.n5'\n",
    "fix_zarr = zarr.open(store=zarr.N5Store(fix_path), mode='r')\n",
    "mov_zarr = zarr.open(store=zarr.N5Store(mov_path), mode='r')\n",
    "\n",
    "# get pointers to the low res scale level\n",
    "fix_lowres = fix_zarr['/lowres']\n",
    "mov_lowres = mov_zarr['/lowres']\n",
    "\n",
    "# we need the voxel spacings for the low res data sets\n",
    "fix_meta = fix_lowres.attrs.asdict()\n",
    "mov_meta = mov_lowres.attrs.asdict()\n",
    "fix_lowres_spacing = np.array(fix_meta['pixelResolution']) * fix_meta['downsamplingFactors']\n",
    "mov_lowres_spacing = np.array(mov_meta['pixelResolution']) * mov_meta['downsamplingFactors']\n",
    "fix_lowres_spacing = fix_lowres_spacing[::-1]  # put in zyx order\n",
    "mov_lowres_spacing = mov_lowres_spacing[::-1]\n",
    "\n",
    "# sanity check: print the voxel spacings and lowres dataset shapes\n",
    "print(fix_lowres_spacing, mov_lowres_spacing)\n",
    "print(fix_lowres.shape, mov_lowres.shape)\n",
    "\n",
    "# get pointers to the high res scale level\n",
    "fix_highres = fix_zarr['/highres']\n",
    "mov_highres = mov_zarr['/highres']\n",
    "\n",
    "# we need the voxel spacings for the high res data sets\n",
    "fix_meta = fix_highres.attrs.asdict()\n",
    "mov_meta = mov_highres.attrs.asdict()\n",
    "fix_highres_spacing = np.array(fix_meta['pixelResolution']) * fix_meta['downsamplingFactors']\n",
    "mov_highres_spacing = np.array(mov_meta['pixelResolution']) * mov_meta['downsamplingFactors']\n",
    "fix_highres_spacing = fix_highres_spacing[::-1]\n",
    "mov_highres_spacing = mov_highres_spacing[::-1]\n",
    "\n",
    "# sanity check: print the voxel spacings and lowres dataset shapes\n",
    "print(fix_highres_spacing, mov_highres_spacing)\n",
    "print(fix_highres.shape, mov_highres.shape)\n",
    "\n",
    "# write data to view in fiji or similar\n",
    "# here we write the highres data to disk, which requires loading it all into memory\n",
    "# this is fine for tutorial data, but in practice you would not do this with your\n",
    "# large data\n",
    "tifffile.imsave('./fix_lowres_data.tiff', fix_lowres[...])\n",
    "tifffile.imsave('./mov_lowres_data.tiff', mov_lowres[...])\n",
    "tifffile.imsave('./fix_highres_data.tiff', fix_highres[...])\n",
    "tifffile.imsave('./mov_highres_data.tiff', mov_highres[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "---\n",
    "\n",
    "Pre-packaged pipelines for specific projects or papers are implemented in the `bigstream.application_pipelines` module. These pipelines chain together multiple alignment steps from more fundamental bigstream alignment functions. To learn about those more fundamental alignment functions, you should later work through the `bigstream_intro_tutorial.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, familiarize yourself with the easifish_registration_pipeline API\n",
    "from bigstream.application_pipelines import easifish_registration_pipeline\n",
    "print(\"easifish_alignment_pipeline\\n\", easifish_registration_pipeline.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigstream.application_pipelines import easifish_registration_pipeline\n",
    "\n",
    "# Arguments for your distributed system\n",
    "cluster_kwargs = {}\n",
    "\n",
    "# run the pipeline\n",
    "affine, deform, aligned = easifish_registration_pipeline(\n",
    "    fix_lowres, fix_highres, mov_lowres, mov_highres,\n",
    "    fix_lowres_spacing, fix_highres_spacing,\n",
    "    mov_lowres_spacing, mov_highres_spacing,\n",
    "    blocksize=[128,]*3,\n",
    "    write_directory='./',\n",
    "    cluster_kwargs=cluster_kwargs,\n",
    ")\n",
    "\n",
    "# the affine and deform are already saved to disk, but we also want to view the aligned\n",
    "# result to make sure it worked.\n",
    "# reformat the aligned data to open in fiji (or similar) - again this works for tutorial data\n",
    "# but you would do this differently for actually larger-than-memory data\n",
    "tifffile.imsave('./aligned.tiff', aligned[...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CircuitSeeker",
   "language": "python",
   "name": "circuitseeker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
